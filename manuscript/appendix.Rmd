# Protocol amendments {#appA}

The study protocol (rationale, methods, and analysis plan) was pre-registered on April 7th 2018 (https://osf.io/eh5qd/). In order to extend the sampling frame and make other minor methodological adjustments, an amended protocol was registered part way through data collection on May 1st 2019 (https://osf.io/pdvb5/). Appendix Table \@ref(tab:protocolAmendments) outlines amendments between the pre-registered protocol, amended protocol, and final report.

```{r protocolAmendments}
tibble(
  "Issue" = c("Sampling frame", "Definition of pre-replication assessment period", "Exclusion of replication year from qualitative assessment", "Automated extraction of citation contexts and replication co-citation", "Counter-arguments", "Dual-coding for citation valence classification", "Examination of characteristics of articles providing counter-arguments.","Renaming of two citation patterns", "Data exclusions", "Citations to replication studies and co-citation of original studies"),
  "Amendment" = c("The end date of the sampling frame was initially April 6th 2018 (see pre-registered protocol). Later, we decided to extend the sampling frame to April 26th 2019 to learn more about how the citation curves developed over time (see amended protocol). Finally, we decided to extend the sampling frame to December 31st 2019 to ensure we had all citations for the year 2019.", "Initially, the pre-replication assessment period was defined as 2015 (i.e., replication year - 1) for the Registered Replication Report cases and all pre-replication years for the other cases. In practice, when the replication year - 1 definition is used for all cases, only one study (Caruso) has a citing article outside of this period, and it is only a single article. Therefore, we have decided that it is more straightforward to use the same definition of the pre-replication assessment period (replication year - 1) for all cases.", "The pre-registered protocol neglected to mention that we intended to exclude the replication year from qualitative assessment. This change was documented in the amended protocol.", "Initially, we intended to use Matlab code to partly automate the extraction of ‘citation contexts’ (text surrounding in-text citations) and identify replication co-citation. However, we found that the size of the relevant citation context varied substantially between articles, so we decided to extract all citation contexts manually. We also decided to identify replication co-citation manually too. These changes were documented in the amended protocol.","In the amended protocol, we clarified that we would attempt to identify counter-arguments in all articles that cited the original study and the replication study.", "Initially, we planned to dual code small batches of articles depending on the degree of inter-rater reliability. However, we encountered a number of somewhat ambiguous cases in our initial coding which suggested there may be more subjectivity involved in the classification of citation valence than we had originally anticipated. For example, an article may contain several favourable statements and several unfavourable statements, in which case one needs to determine how to appropriately weight those statements in order to arrive at a classification that accurately represents the author’s viewpoint. To address this, we decided to minimize subjectivity by dual-coding all articles, with disagreements resolved through discussion (with a third coder if necessary). This is documented in the amended protocol.", "After completing the study we thought it would be informative to examine the article types and journals of articles that provided counter-arguments, and any overlap in authorship with the original study authors or prior collaborators of the first authors of the original studies. These analyses were not pre-registered.", "After completing the study we decided to revise the following terminology from the protocol in order to improve clarity: “principled defence” was changed to “explicit defence” and “hollow defence” was changed to “absent defence”.", "The criteria to exclude data from qualitative assessment (no access, non-English language, and no original study citation in the main text, were not pre-registered. These exclusions were necessary because they precluded the qualitative assessment.","Upon reviewer request, we obtain citation counts for replication studies and checked if they co-cited the relevant original study. These results are presented in Supplementary Information D.")
) %>%
  kable(booktabs=T,longtable=T,caption = "Protocol amendments.") %>%
  column_spec(1,width='4cm') %>%
  column_spec(2,width='11cm')
```

# Random sampling and extrapolation procedures for Baumeister case study {#appB}

Due to a large number of citations, qualitative assessment in the Baumeister case was based on a random sample of 40% of citing articles in each of the pre-replication and post-replication time periods. We used the ‘sample’ function in the programming language R to draw random samples. Because the sampling frame was extended on three occasions (see Supplementary Information A), it was necessary to obtain random samples three times in order to maintain coverage of 40% for each time period. As we aimed to achieve a 40% sample across each time period, an equal sample in each individual year was not guaranteed, and in fact the proportion of citations coded in the post-refutation period does differ between years (48% 49%, and 23% respectively).

We extrapolated the valence classifications and co-citation of replications from the random sample to all citing articles in the pre-replication (2015) and post-replication (2017, 2018, 2019) assessment periods. To do this, we multiplied each category count in a given year by the reciprocal of the proportion coded in that year. For example, in 2017, we classified 71 citations as ‘favorable’ amongst the 48% of citations coded in that year, so to extrapolate we computed 71*1/0.48 = 148.

# Non-standardized data for citation curves, citation valence, and co-citation of replications {#appC}

```{r tabularData, results = "asis"}
options(knitr.kable.NA = "-") # set symbol to use for NA cells

d_summary %>%
  filter(case == 'baumeister' & pubYear %in% c(2015,2017,2018,2019) |
         case == 'strack' & pubYear %in% c(2015,2017,2018,2019) |
         case == 'sripada' & pubYear %in% c(2015,2017,2018,2019) |
         case == 'carter' & pubYear %in% c(2013,2015,2016,2017,2018,2019) |
         case == 'caruso' & pubYear %in% c(2013,2015,2016,2017,2018,2019)) %>%
  mutate(favourable = paste0(favourable,' (',round(favourable_prop*100,0),'%)'),
         unfavourable = paste0(unfavourable,' (',round(unfavourable_prop*100,0),'%)'),
         equivocal = paste0(equivocal,' (',round(equivocal_prop*100,0),'%)'),
         unclassifiable = paste0(unclassifiable,' (',round(unclassifiable_prop*100,0),'%)'),
         excluded = paste0(excluded_yes,' (',round(excluded_yes_prop*100,0),'%)'),
         citesRep = paste0(citesRep_yes,' (',round(citesRep_yes_prop*100,0),'%)'),
         citesRep = ifelse(case %in% c('baumeister','sripada','strack') & pubYear == 2015, NA, citesRep), # set citesRep to NA in pre-replication year
         citesRep = ifelse(case %in% c('carter','caruso') & pubYear == 2013, NA, citesRep)) %>% # set citesRep to NA in pre-replication year
  select(year = pubYear, `citing\narticles` = citesTarget, excluded, unclassifiable, favourable, equivocal, unfavourable, citesRep) %>%
  kable(caption = 'Raw counts and percentages for citations to the original study, exclusions, citation valence, and concomitant citations to the replication study in qualitative assessment period. In the Baumeister case, numbers in square brackets in the citations column are the number of citing articles included in the random samples drawn from the pre-replication and post-replication time periods. Percentages for the Baumeister case are extrapolations based on the random samples.', booktabs=T, longtable=T) %>%
  pack_rows("Baumeister", 1, 4) %>%
  pack_rows("Sripada", 5, 8) %>%
  pack_rows("Strack", 9, 12) %>%
  pack_rows("Carter", 13, 18) %>%
  pack_rows("Caruso", 19, 24)
```

```{r citeCurvesRaw, fig.cap='Annual citation counts (non-standardized; solid line) for the five original studies. The black arrow indicates the year in which the replication was published.', fig.width=12, fig.height=12.5, fig.path='figs/', dev=c('png', 'pdf')}
ggarrange(
  ggarrange(citationCurve("strack", thisTitle = "Strack et al. (1988)", standardized = F, plotReference = F, areaPlot = F),
    citationCurve("baumeister", thisTitle = "Baumeister et al. (1998)", standardized = F, plotReference = F, areaPlot = F),
    nrow = 2, ncol = 1, common.legend = T
  ),
  ggarrange(citationCurve("sripada", thisTitle = "Sripada et al. (2014)", standardized = F, plotReference = F, areaPlot = F),
    citationCurve("carter", thisTitle = "Carter et al. (2011)", standardized = F, plotReference = F, areaPlot = F),
    citationCurve("caruso", thisTitle = "Caruso et al. (2013)", standardized = F, plotReference = F, areaPlot = F),
    nrow = 1, ncol = 3, common.legend = F
  ),
  nrow = 2, ncol = 1, heights = c(2, 1)
) %>%
  annotate_figure(
    left = text_grob("Citation count (non-standardized)", rot = 90, size = 20),
    bottom = text_grob("Publication year", size = 20)
  )
```

```{r}
# data summarised for post-replication period
d_summary_postrep <- d_summary %>%
  filter(year == 'post-replication') %>%
  mutate(favourable = paste0(favourable,' (',round(favourable_prop,2),')'),
         unfavourable = paste0(unfavourable,' (',round(unfavourable_prop,2),')'),
         equivocal = paste0(equivocal,' (',round(equivocal_prop,2),')'),
         unclassifiable = paste0(unclassifiable,' (',round(unclassifiable_prop,2),')'),
         excluded = paste0(excluded_yes,' (',round(excluded_yes_prop,2),')'),
         citesRep = paste0(citesRep_yes,' (',round(citesRep_yes_prop,2),')')) %>%
  select(case, year = pubYear, `citing\narticles` = citesTarget, excluded, unclassifiable, favourable, equivocal, unfavourable, citesRep)
```

# Citations to replication studies and co-citation of original studies {#appD}

Upon reviewer request, we examined citation counts for replication studies and checked whether citing articles also co-cited the relevant original study. To obtain the data, we downloaded bibliographic records from the Clarivate Analytics Web of Science Core Collection accessed via the University of Amsterdam on 16th April, 2021 for articles that cited each replication study (up to the study endpoint - December, 2019) and cross-checked them with our sample of articles that cited the original study. As shown, the replication studies also have a life of their own and they are often cited independently of the specific original study. Often this is easy to explain, e.g., Klein et al. replicated 13 original studies, not just the two that were of interest in our analysis. These studies are also likely to have accrued citations by virtue of being amongst the first highly prominent examples of preregistered multi-laboratory replications in psychology.


```{r}
# identify how many studies citing the replication also cite the original study

## extract citing articles for replication studies and original studies
d_kleinCites <- d_repCitations %>% filter(case == 'klein')
d_wagenmakersCites <- d_repCitations %>% filter(case == 'wagenmakers')
d_haggerCites <- d_repCitations %>% filter(case == 'hagger')
d_baumeisterCites <- d_citations %>% filter(case == 'baumeister')
d_sripadaCites <- d_citations %>% filter(case == 'sripada')
d_carusoCites <- d_citations %>% filter(case == 'caruso')
d_carterCites <- d_citations %>% filter(case == 'carter')
d_strackCites <- d_citations %>% filter(case == 'strack')

## compute citation counts for replication studies
hagCites <- nrow(d_haggerCites)
wagenCites <- nrow(d_wagenmakersCites)
kleinCites <- nrow(d_kleinCites)

## compute how many articles citing the replication study also cite the relevant original study
hagBauCocites <- sum(d_haggerCites$UT %in% d_baumeisterCites$UT)
hagSriCocites <- sum(d_haggerCites$UT %in% d_sripadaCites$UT)
wagenStrackCocites <- sum(d_wagenmakersCites$UT %in% d_strackCites$UT)
kleinCartCocites <- sum(d_kleinCites$UT %in% d_carterCites$UT)
kleinCaruCocites <- sum(d_kleinCites$UT %in% d_carusoCites$UT)

## build table
repCociteTable <- data.frame(
  "Replication" = c("Hagger et al. (2016)", "Klein et al. (2014)", "Wagenmakers et al. (2016)"),
  "Citation" = c(hagCites, kleinCites, wagenCites),
  "Cocitations" = c(paste0(hagBauCocites," (Baumeister et al. 1998) ",hagSriCocites," (Sripada et al. 2014)"), paste0(kleinCartCocites," (Carter et al. 2011) ",kleinCaruCocites," (Caruso et al. 2012)"), paste0(wagenStrackCocites," (Strack et al. 1988)"))
  )
```

```{r}
repCociteTable %>% kable(col.names = c("Replication study", "Citation count","Cocitations of original study"), caption = 'Citations counts for replication studies and co-citation counts to relevant original studies.', booktabs=T)
```





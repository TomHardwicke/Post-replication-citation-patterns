---
title: "Post-replication citation patterns in psychological science: Preliminary analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = T)
```

```{r load_packages}
library(knitr) # for literate programming
library(papaja) # for article template
library(tidyverse) # for data munging
library(tidylog) # inline analysis feedback
library(here) # for finding files
library(ggpubr) # for arranging plots
library(kableExtra) # for tables 
```

```{r perform_preprocessing}
# loads raw data, performs preprocessing, saves preprocessed files
source(here('analysis','preprocessing.R'))
```

```{r load_data}
# loads the processed data files output by the preprocessing performed above
load(here('data','processed','d_citations.R'))
load(here('data','processed','d_reference.R'))
load(here('data','processed','d_contentAnalysis.R'))
```

```{r load_functions}
# load custom functions
source(here('analysis','functions.R'))
```

```{r add_standardized_citation_counts}
# identify the five different case studies we are looking at
caseNames <- c('baumeister', 'sripada', 'strack', 'carter', 'caruso')
replicationYears <- c(2016, 2016, 2016, 2014, 2014)

# set up some colour palettes
library(RColorBrewer)
p1 <- c('lightgrey','darkgrey', brewer.pal(3, "Pastel2")[1], brewer.pal(3, "Pastel2")[2], brewer.pal(4, "Pastel1")[4])
p2 <- c('lightgrey', brewer.pal(3, "Pastel2")[3], brewer.pal(4, "Pastel1")[1])

# summarizes data at the year level for each case and adds standardized citation counts for target citations and reference class citations
d_summary <- data.frame() # create empty list to hold data frames for each case
for(i in seq(1,5)){ # loop through cases
  d <- standardizeCitations(
    citationData = d_citations %>% filter(case == caseNames[i]), 
    referenceData = d_reference %>% filter(case == caseNames[i]),
    contentData = d_contentAnalysis %>% filter(case == caseNames[i]),
    replicationYear = replicationYears[i])
  d_summary <- bind_rows(d_summary, d) # append to dataframe
}
```

Hi all,

We've now completed all planned data collection and coding for this project. This report contains a preliminary analysis of the data conducted by Tom & Sophia. The study protocol(s) can be found here:

* Original protocol: https://osf.io/eh5qd/
* Amended protocol (we added more up-to-date citation data): https://osf.io/pdvb5/

# Citation count analysis

## Raw citations

Firstly, we'll plot raw citation curves for the five cases to get a flavour of what we are working with. The x-axis starts in the year the target study was published. The black arrow indicates the publication date of the contradictory replication study. The black line represents the raw annual citation count to the target article. Note that the citation data was acquired from the WOS database on April 26th, 2019, which partly contributes to the fall in citations in 2019 in all cases.

Throughout this report, we've made larger plots for the Baumeister and Strack cases because their citation counts are substantially larger than the other cases (Sripada, Carter, Caruso).

```{r fig.height = 6, fig.width = 8}
ggarrange(citationCurve('strack', standardized = F, plotReference = F),
          citationCurve('baumeister', standardized = F, plotReference = F),
          nrow = 2, ncol = 1, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Raw citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

```{r fig.height = 3, fig.width = 8}
ggarrange(citationCurve('sripada', standardized = F, plotReference = F),
          citationCurve('carter', standardized = F, plotReference = F),
          citationCurve('caruso', standardized = F, plotReference = F),
          nrow = 1, ncol = 3, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Raw citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

## Standardized citations with reference class

Now we'll plot standardized citation curves and include citations to the set of reference articles (the dashed grey line). In the graphs below, the annual citation counts for both the target article and reference class are standardized against the calendar year with the highest citation count for the target article (i.e., citations received in that year are set at the standardized value of 100). As defined in the protocol, the reference class in each case is all of the articles published in the same year and in the same journal as the target article. For example, for Baumeister et al. (1998), the reference class is all articles published in 1998 in the Journal of Personality and Social Psychology.

```{r fig.height = 6, fig.width = 8}
ggarrange(citationCurve('strack', standardized = T, plotReference = T),
          citationCurve('baumeister', standardized = T, plotReference = T),
          nrow = 2, ncol = 1, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

```{r fig.height = 3, fig.width = 8}
ggarrange(citationCurve('sripada', standardized = T, plotReference = T),
          citationCurve('carter', standardized = T, plotReference = T),
          citationCurve('caruso', standardized = T, plotReference = T),
          nrow = 1, ncol = 3, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

## Issues

Before moving on, there are a few things to note or questions I want to raise:

(1) As mentioned above, the fall in citations in 2019 is partly due to the citation data being acquired part way through the year (April 26th, 2019). Now we are in 2020, it should be straightforward to update these curves with all of the 2019 data - however this may create complications for overlaying the qualitative data (next section) on the citation curves because (1) previous years will likely have some minor changes due to database updates (hopefully they'll be so few changes we can update our qualitative assessment without too much trouble); (2) 2019 will be left with a large gap, unless we code additional articles.

(2) Does it make sense to standardize the citation counts to 100 when the raw counts are below 100 for all cases other than Baumeister?

(3) Can we really learn much from the Sripada, Caruso, and Carter cases given the low citation count?

# Qualitative assessment of citation content

We conducted a qualitative assessment of citing articles within a pre-defined "assessment period". The assessment period included the year prior to and all years after publication of the replication. We assessed all citing articles in the assessment period except for in the Baumeister case - due to a very large number of citing articles we only examined a random sample of 40% of the citing articles from the assessment period, specifically 2015 (n = 76) and 2017 to April 2019 (n = 177). In all cases, the assessment period does not include the year in which the replication was published. This is because articles may already be in the publication pipeline for which the authors have no knowledge of the results of the contradictory replication.

Across all cases, `r d_contentAnalysis %>% count(excluded) %>% filter(excluded == T) %>% pull(n)` citing articles had to be excluded because they could not be accessed (n = `r d_contentAnalysis %>% count(exclusionReason) %>% filter(exclusionReason == "No access") %>% pull(n)`), were non-English language (n = `r d_contentAnalysis %>% count(exclusionReason) %>% filter(exclusionReason == "Non-English language") %>% pull(n)`), or because the target article was cited in the references but not in the actual text (n = `r d_contentAnalysis %>% count(exclusionReason) %>% filter(exclusionReason == "Cited in references but not in text") %>% pull(n)`). Excluded articles are represented on the graphs below in light grey.

## Claim correction vs. claim perpetuation

One goal of the study was to see if we would observe a post-replication pattern more consistent with "claim correction" or "claim perpetuation".

A claim correction pattern might involve a decrease in the number of favourable citations reflecting declining field-level endorsement of the original claim. This may be accompanied by an increase in the number of unfavourable citations (an active correction effect) or no change/decline in the number of unfavourable citations (a passive correction effect). 

A claim perpetuation pattern might involve an increase or maintain of the number of favourable citations reflecting increasing or maintained field-level endorsement of the original claim. This may be accompanied by an increase in the number of unfavourable citations (a challenged perpetuation effect) or no change/decline in the number of unfavourable citations (an unchallenged perpetuation effect).

To assess this, we classified citations to the target article as favourable, equivocal, unfavourable, or unclassifiable (a general or methodological reference not related to belief in the claim under scruntiny). Each article was coded by two individuals with disagreements resolved through discussion/arbitration. The data shown below represents the agreed upon classifications.

```{r fig.height = 6, fig.width = 8}
ggarrange(citationCurve('strack', areaPlot = 'classification'),
          citationCurve('baumeister', areaPlot = 'classification'),
          nrow = 2, ncol = 1, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

```{r fig.height = 3, fig.width = 8}
ggarrange(citationCurve('sripada', areaPlot = 'classification'),
          citationCurve('carter', areaPlot = 'classification'),
          citationCurve('caruso', areaPlot = 'classification'),
          nrow = 1, ncol = 3, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

Recall that we only examined 40% of the articles in the Baumeister case which is why there's a lot of white space. 

It may be helpful to zoom in on the relevant part of the timeline too to take a closer look (we'll just do this for Strack and Baumeister):

```{r fig.height = 3, fig.width = 8}
ggarrange(citationCurve('strack', areaPlot = 'classification', zoom = T),
          citationCurve('baumeister', areaPlot = 'classification', zoom = T),
          nrow = 1, ncol = 2, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

There's a (to me) surprising preponderance of favourable citations in both cases - consistent with a "claim perpetuation" pattern. This is arguably 'unchallenged' because there are very few unfavourable citations. Here are the data in tabular format:

```{r}
d_summary %>%
  filter(case == 'baumeister',
         pubYear %in% c(2015,2017,2018,2019)) %>%
  select(year = pubYear, targetCitations = citesTarget, favourable, equivocal, unfavourable, unclassifiable, excluded = excluded_yes) %>%
  kable(caption = 'BAUMEISTER') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'strack',
         pubYear %in% c(2015,2017,2018,2019)) %>%
  select(year = pubYear, targetCitations = citesTarget, favourable, equivocal, unfavourable, unclassifiable, excluded = excluded_yes) %>%
  kable(caption = 'STRACK') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'sripada',
         pubYear %in% c(2015,2017,2018,2019)) %>%
  select(year = pubYear, targetCitations = citesTarget, favourable, equivocal, unfavourable, unclassifiable, excluded = excluded_yes) %>%
  kable(caption = 'SRIPADA') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'carter',
         pubYear %in% c(2013,2015,2016,2017,2018,2019)) %>%
  select(year = pubYear, targetCitations = citesTarget, favourable, equivocal, unfavourable, unclassifiable, excluded = excluded_yes) %>%
  kable(caption = 'CARTER') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'caruso',
         pubYear %in% c(2013,2015,2016,2017,2018,2019)) %>%
  select(year = pubYear, targetCitations = citesTarget, favourable, equivocal, unfavourable, unclassifiable, excluded = excluded_yes) %>%
  kable(caption = 'CARUSO') %>%
  kable_styling(full_width = F)
```

## Citation balance vs. citation bias

We examined whether articles that cite the target study also cite the contradictory replication (a 'balanced citation effect') or neglect to do so (a 'citation bias effect').

Here we are only looking at articles published in the post-replication period because only they had the opportunity to cite the replication. Recall that this period does not include the year in which the replication was published.

```{r fig.height = 6, fig.width = 8}
ggarrange(citationCurve('strack', areaPlot = 'citesReplication'),
          citationCurve('baumeister', areaPlot = 'citesReplication'),
          nrow = 2, ncol = 1, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

```{r fig.height = 3, fig.width = 8}
ggarrange(citationCurve('sripada', areaPlot = 'citesReplication'),
          citationCurve('carter', areaPlot = 'citesReplication'),
          citationCurve('caruso', areaPlot = 'citesReplication'),
          nrow = 1, ncol = 3, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

It may be helpful to zoom in on the relevant part of the timeline too to take a closer look (we'll just do this for Strack and Baumeister):

```{r fig.height = 3, fig.width = 8}
ggarrange(citationCurve('strack', areaPlot = 'citesReplication', zoom = T),
          citationCurve('baumeister', areaPlot = 'citesReplication', zoom = T),
          nrow = 1, ncol = 2, common.legend = T) %>% 
  annotate_figure(
    left = text_grob("Standardized citation count", rot = 90),
    bottom = text_grob("Publication year"))
```

Here's the data in tabular format:

```{r}
d_summary %>%
  filter(case == 'baumeister',
         pubYear %in% c(2017,2018,2019)) %>%
  mutate(replicationCitations_percent = round((citesRep_yes/citesTarget)*100,0)) %>%
  select(year = pubYear, targetCitations = citesTarget, excluded = excluded_yes, replicationCitations = citesRep_yes, replicationCitations_percent) %>%
  kable(caption = 'BAUMEISTER') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'strack',
         pubYear %in% c(2017,2018,2019)) %>%
  mutate(replicationCitations_percent = round((citesRep_yes/citesTarget)*100,0)) %>%
  select(year = pubYear, targetCitations = citesTarget, excluded = excluded_yes, replicationCitations = citesRep_yes, replicationCitations_percent) %>%
  kable(caption = 'STRACK') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'sripada',
         pubYear %in% c(2017,2018,2019)) %>%
  mutate(replicationCitations_percent = round((citesRep_yes/citesTarget)*100,0)) %>%
  select(year = pubYear, targetCitations = citesTarget, excluded = excluded_yes, replicationCitations = citesRep_yes, replicationCitations_percent) %>%
  kable(caption = 'SRIPADA') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'carter',
         pubYear %in% c(2015,2016,2017,2018,2019)) %>%
  mutate(replicationCitations_percent = round((citesRep_yes/citesTarget)*100,0)) %>%
  select(year = pubYear, targetCitations = citesTarget, excluded = excluded_yes, replicationCitations = citesRep_yes, replicationCitations_percent) %>%
  kable(caption = 'CARTER') %>%
  kable_styling(full_width = F)
```

```{r}
d_summary %>%
  filter(case == 'caruso',
         pubYear %in% c(2015,2016,2017,2018,2019)) %>%
  mutate(replicationCitations_percent = round((citesRep_yes/citesTarget)*100,0)) %>%
  select(year = pubYear, targetCitations = citesTarget, excluded = excluded_yes, replicationCitations = citesRep_yes, replicationCitations_percent) %>%
  kable(caption = 'CARUSO') %>%
  kable_styling(full_width = F)
```
And here's the data summarised at the case level with percentages:

```{r}
rbind(
  d_summary %>%
  filter(case %in% c('baumeister','strack','sripada'),
         pubYear %in% c(2017,2018,2019)),
  d_summary %>%
    filter(case %in% c('carter', 'caruso'),
           pubYear %in% c(2015,2016,2017,2018,2019))
) %>%
  group_by(case) %>%
  summarise(targetCitations = sum(citesTarget,na.rm=T), 
            replicationCitations = sum(citesRep_yes,na.rm=T)) %>%
  mutate(`replicationCitations (%)` = round((replicationCitations/targetCitations)*100,0)) %>%
  kable(caption = 'Citations to replication study by articles citing target study in post-replication years') %>%
  kable_styling(full_width = F)
```

There seems to be evidence of citation bias (citing the target article but not the replication) in all cases, though the effect size smaller in the Sripada case (probably because this study is probably only well known because of its connection to the Baumeister study - recall that it was used as a methodological proxy for that more influential study in the replication attempt).

## Principled defense vs. hollow defense

Proponents of the original claim may seek to make the case that the contradictory replication actually does not undermine their position. In this case, one might expect counter-arguments that defend the original claim to be presented in articles that cite the replication study and favourably cite the original study.

Here's the data in tabular format:

```{r}
rbind(
  d_summary %>%
  filter(case %in% c('baumeister','strack','sripada'),
         pubYear %in% c(2017,2018,2019)),
  d_summary %>%
    filter(case %in% c('carter', 'caruso'),
           pubYear %in% c(2015,2016,2017,2018,2019))
) %>%
  group_by(case) %>%
  summarise(counterargs_yes = sum(counterargs_yes,na.rm=T),
            counterargs_no = sum(counterargs_no,na.rm=T)) %>%
  mutate(
    `Replication cited` = counterargs_yes+counterargs_no,
    counterargs_percent = round(
    (counterargs_yes/(`Replication cited`))*100,
    0)) %>%
  select(case,
         `Replication cited`,
         `Counter arguments used` = counterargs_yes,
         -counterargs_no,
         `Counter arguments used (%)` = counterargs_percent) %>%
  kable(caption = 'Use of counter arguments when target study cited favourably and replication study cited') %>%
  kable_styling(full_width = F)
```

The numbers are quite small here because we are looking only at articles that cited the target study and also cited the replication study favourably (note we actually coded for counter arguments whenever the replication study was cited, but this doesn't increase the counts a great deal as is less straightforward to interpret). It looks like there are examples of 'principled defense' (citing the target study favourably and providing counter arguments against the replication) and 'hollow defense' (citing the target study favourably but providing no counter arguments against the replication), with a tendency towards the latter.
